什么是Nacos：一个更易于构建云原生应用的动态服务发现，配置管理和服务管理平台。
就是注册中心+配置中心的组合。
Nacos=Eureka+Config+ Bus ,用过后面三个的，都会知道有很多bug

下载地址
https://github.com/alibaba/nacos/tags

解压之后，一定搭建好nacos的数据库环境配置
conf\nacos-mysql.sql 弄到数据库中

运行bin下面的startup.cmd   单机启动  默认是集群
startup.cmd -m standalone

之后创建服务提供者cloudalibaba-provider-payment9003 | cloudalibaba-provider-payment9002
nacos会自动提供负载均衡

然后编写服务调用者
注意一定要添加配置类 否则无法使用服务的负载均衡

几种注册中心的比较
名称                      CAP模型               控制台管理           社区活跃度
Eureka                      AP                  支持              低 （2.x版本闭源）
Zookeeper                   CP                  不               中
Consul                      CP                  支持              高
Nacos                       AP                  支持              高

目前NacosAP和CP 2种都是支持的。
CAP理论核心：一个分布式系统不可能同时很好的满足 一致性，可用性，分区容错 这三个需求。
将Nosql分成了 CA  CP  AP
CA,单点集群，满足一致性，可用性， 可扩展性不太强大
CP 一致性，分区容忍，性能不是特别高
AP 可用性，分区容忍  通常可能对一致性要求低一些。

C是所有节点在同一时间看到的数据是一致的，而A的定义是所有的请求都会收到响应

何时选择用何种模式？
一般来说
如果不需要存储服务级别的信息且服务实例是通过nacos-client
注册，并能够保持心跳上报，那么就可可以选择AP模式，当前主流的服务如SpringCloud，Dubbo，
都适用于AP模式，AP模式为了服务的可能性而减弱了一致性，因此AP模式下只支持注册临时实例。


如果需要在服务级别编辑或存储配置信息，那么CP是必须，K8S服务和DNS服务则适用于CP模式。
CP模式下则支持注册持久化实例，此时则是以Raft协议为集群运行模式，该模式下注册实例之前必须
先注册服务，如果服务不存在，则会返回错误。

这样切换
curl -X PUT '$NACOS_SERVER:8848/nacos/v1/ns/operator/switches?entry=serverMode&value=CP'

Nacos作为配置中心
新建cloudalibaba-config-nacos-client3377
@RefreshScope 通过Spring Cloud原生注解RefreshScope实现配置自动更新


在Nacos SpringCloud中  dataId完整格式如下
${prefix}-${spring.profile.active}.${file-extension}

prefix默认为spring.application.name的值,也可以通过配置项spring.cloud.nacos.config.prefix
来配置。

spring.profile.active即为当前环境对应的profile,详情可以参考SpringBoot文档。
注意：当spring.profile.active为空时,对应的连接符 - 也将不存在，dataId的拼接格式
变成${prefix}.${file-extension}



file-extension为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension
来配置。目前只支持properties和yaml类型。

最好先成全名 不要省略${prefix}
创建nacos-config-client-dev.yaml文  内容为  info后面的可以为字符串 也可以不加字符串
config:
    info: config in for dev ,from nacos config center.verson=1

之后就修改config配置文件，直接调用会直接刷新。


Namespace和Group+DataID 三者的关系
类似于java的包名和类名
最外层的namespace是可以用于区分部署环境的。Group和DataID逻辑上区分两个目标对象
默认情况
Namespace=public            Group=DEFAULT_GROUP         默认Cluster是DEFAULT

Nacos默认的命令空间是public，Namespace主要用来实现隔离
比方说我们现在有三个环境，开发，测试，生产环境，我们就可以创建三个Namespace，
不同的Namespace之间是隔离的。
Group默认是DEFAULT_GROUP，Group可以把不同的微服务划分到同一个分组里面去。

Service就是微服务；一个service可以包含多个Cluster（集群）
Nacos默认Cluster是DEFAULT，Cluster是对指定微服务的一个虚拟划分。

比方说为了容灾，将Service微服务分别部署在杭州机房和广州机房，
这时就可以给杭州机房的service微服务起一个集群名称（HZ）
给广州的机房Service微服务起一个集群名称（GZ），还可以尽量让同一个机房的微服务互相调用，
以提升性能。
最后是Instance就是微服务的实例。


搭建nacos集群
nginx下载地址
http://nginx.org/en/download.html
下载稳定版1.18 或者最新版1.19

nginx集群+3台nacos机器+数据库集群（或者主从备份）
先安装依赖包
yum -y install pcre-devel

yum -y install openssl-devel

yum -y install gcc

yum -y install lrzsz

yum -y install openssh-clients

或者输入
yum -y install pcre-devel openssl-devel gcc lrzsz openssh-clients

之后上传nginx安装包 解压
进入执行
./configure
然后执行
make install
会在/usr/local/nginx 这边是生成的路径
复制conf里面的nginx.conf到外面
启动nginx命令
./nginx -s stop
./nginx -s quit
./nginx -s reload
然后指明配置文件
./nginx -c   xxxxxpath
测试nginx配置文件是否有误
./nginx -t


./nginx -c /app/nginx/conf/nginx.conf

nacos集群搭建参考网址
https://blog.csdn.net/molihuakai_118/article/details/108315719?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161577856016780271545098%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=161577856016780271545098&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-108315719.first_rank_v2_pc_rank_v29&utm_term=springcloud+nacos%E6%90%AD%E5%BB%BA%E6%9C%8D%E5%8A%A1%E9%9B%86%E7%BE%A4

下载nacos的linux版本解压  1.1.4和1.4完全是2个版本，搭建集群方式是不一样的。
启动是执行startup.sh

创建数据库并且设置编码
CREATE DATABASE IF NOT EXISTS nacos_config DEFAULT CHARSET utf8 COLLATE utf8_general_ci;
修改application.properties
#将下面的配置的信息设置你的真实ip
spring.datasource.platform=mysql
db.num=1
db.url.0=jdbc:mysql://192.168.232.104:3306/nacos_config?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&useUnicode=true&useSSL=false&serverTimezone=UTC
db.user=root
db.password=root
db.password=root

查看防火墙状态：firewall-cmd --state

启动防火墙：systemctl start firewalld.service

关闭防火墙：systemctl stop firewalld.service

重启：systemctl restart firewalld.service

开机启用：systemctl enable firewalld.service

禁止开机启动：systemctl disable firewalld.service





第1种方式  在3个机器上分别安装nacos
备份下面这个文件
cp cluster.conf.example cluster.conf

vim cluster.conf

设置端口
192.168.16.101:8848
192.168.16.102:8848
192.168.16.103:8848




之后分别启动bin路径下的startup.sh
sh startup.sh  之后集群就可以看到效果了
但是，每次访问都要根据id:端口访问 所以设置nginx来访问

nginx配置文件在外面



下载自带的jdk
#检查是否存在jdk
rpm -qa|grep java
#卸载
rpm -e --nodeps

vim /etc/profile
#set java enviroment
export JAVA_HOME=/app/java/jdk/jdk1.8.0_281
export JRE_HOME=/app/java/jdk/jdk1.8.0_281/jre
export CLASSPATH=.:$JAVA_HOME/lib$:JRE_HOME/lib:$CLASSPATH
export PATH=$JAVA_HOME/bin:$JRE_HOME/bin/$JAVA_HOME:$PATH

使配置文件生效
[root@localhost java]# source /etc/profile
测试

java-version

启动nginx指明配置文件
[root@localhost sbin]# ./nginx -c /app/nginx/nginx-1.8.0/conf/nginx.conf


---------------------------------------
开始学习Sentinel熔断和限流
官网
https://github.com/alibaba/Sentinel/wiki/%E4%BB%8B%E7%BB%8D

Hystrix缺点
1.需要我们程序员自己手工搭建监控平台。
2.没有一套web界面可以给我们进行更加细粒度得配置
流控，速率控制，服务熔断，服务降级。


阿波罗配置管理中心，只是听说

Sentinel ，分布式系统的流量防卫兵
1.独立一个组件，可以独立出来
2.直接界面化的细粒度统一配置。（约定>配置>编码）
都可以写在代码里面，但是我们本次还是大规模的学习使用配置和注解的方式，尽量少写代码。
3.Sentinel 承接了阿里巴巴近 10 年的双十一大促流量的核心场景，例如秒杀

怎么安装和配置
下载地址
https://github.com/alibaba/Sentinel/releases
可以用1.7或者1.8
下载jar包
直接可以运行在java环境，需要注意，端口8080不要被占用
java -jar sentinel-dashboard-1.7.1.jar
之后就可以访问http://localhost:8080
账号密码都是sentinel

之后怎么整合到项目中
新建8401项目
cloudalibaba-sentinel-service8401
搭建好之后访问接口进行测试
之后再访问就可以看到效果了
http://localhost:8080/#/dashboard/metric/cloudalibaba-sentinel-service

流控规则
资源名:唯一名称，默认请求路径

针对来源：Sentinel可以针对调用者进行限流，填写微服务名，默认default(不区分来源)

阈值类型/单机阈值
    QPS（每秒钟的请求数量）：当调用该API的QPS达到阈值的时候，进行限流
    线程数：当调用该API的线程数达到阈值的时候，进行限流。
    (2个东西不一样，OPS：所有的请求都在外面，在外面进行拦截，一秒一次 其他的拦截。 而线程数是在门里面，
    进行拦截，只能有一个线程)
是否集群：不需要集群

流控模式：
    直接：API达到限流条件时，直接限流
    关联：当关联的资源达到阈值时，就限流自己（当与A关联的资源B达到阈值后，就限流自己，简单来说，B惹事，A挂了，这种场景，比如说支付服务和下单服务，支付挂了就无法下单）。
    链路：只记录指定链路上的流量（指定资源从入口资源进来的流量，如果达到阈值，就进行限流）【api级别的针对来源】

流控效果：
    快速失败：直接失败，抛出异常
    Warm Up:根据codeFactor（冷加载因子，默认3）的值，从阈值/CodeFactor，经过预热时长，才达到设置的QPS阈值（默认 就是阈值/3 开始）
    排队等待：匀速排队，让请求以匀速的速度通过，阈值类型必须设置QPS，否则无效

---------------------------------------------------
使用流控，点击簇点链路，按钮来添加
默认选择，针对来源选择default，阈值类型，qps，单机阈值为1 确定就可以了
表示1秒钟内查询一次就是OK，若超过次数1，就直接--快速失败，报默认错误。
之后快速访问的时候就会直接出错。


但是这样调用的是默认的报错信息，技术方面OK，是否应该有我们自己的后续处理
兜底方法，分为系统默认和客户自定义 2种

从HystrixCommand 到@SentinelResource

使用postman进行并发压力测试。流控模式选择关联，对A进行编辑，
关联资源为/testB ,当频繁调用testB， B满足了条件，A就不能使用。但是B不会挂，只有A调用的时候会报错。


使用链路方式
资源名为公共接口,为message
入口资源为/info1
1.yml中新增配置
<dependency>
            <groupId>com.alibaba.csp</groupId>
            <artifactId>sentinel-web-servlet</artifactId>
</dependency>

2.yml中修改 spring.application.cloud.sentinel.web-context-unify=false
spring.application.cloud.sentinel.filter.enabled=false
3.新增配置类FilterContextConfig

流控效果Warm Up效果
默认codeFactor 为3 ，即请求QPS从(threshold/3)开始,经多少预热时长才逐渐升至设定的QPS阈值。
案列，阈值为10  ，预热为5秒

系统初始化的阈值为10/3 约等于3，即阈值刚开始为3，然后过了5秒后阈值慢慢升高恢复到10

实际案例：秒杀系统在开启的瞬间，会有很多流量进来，很有可能把系统打死，
预热方式就是为了保护系统，可慢慢的把流量放进来，慢慢的把阈值长到设置的阈值。


匀速排队，让请求以均匀的速度通过，阈值类型必须设成QPS，否则无效。漏桶算法
设置含义：/testA 每秒1次请求，超过的话就排队等待，等待的超时时间为20000毫秒


下面来学习降级规则

RT（平均响应时间，秒级）
    平均响应时间， 超出阈值 且 在时间窗口内通过的请求>=5 2个条件同时满足后触发降级。
    窗口期过后关闭断路器
    RT最大4900（更大的需要通过-Dcsp.sentinel.statistic.max.rt=XXXX 才能生效）

异常比例（秒级）
QPS>=5 且异常比例（妙级统计）超过阈值时，触发降级，时间窗口结束后，关闭降级

异常数（分钟级）
异常数（分钟统计）超过阈值时，触发降级，时间窗口结束后，关闭降级

Sentinel 熔断降级会调用链路中某个资源出现不稳定状态时（例如调用超时或异常比例升高，）对这个资源的调用进行限制，
让请求快速失败，避免影响到其它的资源而导致的级联错误。

当资源呗降级后，在接下来的降级时间窗口之内，对该资源的调用都自动熔断（默认行为是抛出DegradeException）。

Sentinel的断路器是没有半开状态的（1.7没有，1.8之后就有了）。
半开的状态系统自动去检测是否请求有异常，
没有异常就关闭断路器恢复使用，
有异常则继续打开断路器不可用，具体可以参考Hystrix

----------------------------------------
实战慢调用比例SLOW_REQUEST_RATIO（1.7里面不可用，所以我这边版本使用1.8.1的最新版本）
选择慢调用比例作为阈值，需要设置允许的慢调用RT（也就是最大响应时间，默认为毫秒ms，可以设置200毫秒），
请求的响应时间大于该值则统计为慢调用。

当单位统计时长（statIntervalMs）内请求数目 大于设置的最小请求数目， 并且慢调用的
比例大于阈值，则接下来的熔断时长内请求会自动被熔断。

熔断时长：在这段时间内发生熔断，拒绝所有请求。

最小请求数：即允许通过的最小请求数，在该数量内不发生熔断

熔断有三种状态，分别为OPEN，HALF_OPEN,CLOSED
OPEN:表示熔断开启，拒绝所有请求。
HALF_OPEN:探测恢复状态，如果接下来的一个请求顺利通过则结束熔断，否则继续熔断。
CLOSED:表示熔断关闭，顺利通过

经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求响应时间小于设置的
慢调用RT 则结束熔断，若大于设置的慢调用RT则再次被熔断。


最大RT  为1
比例阈值(0-1之间)为0.5
熔断时长:10s
最小请求数:设置为5，每秒5个
统计时长:1000 ms
当资源的响应时间超过最大RT（以ms为单位，最大RT即最大响应时间）之后，资源进入准降级状态。
如果接下来1s内持续进入5个请求（最小请求数），它们的RT都持续超过这个阈值，那么在接下来的熔断时长之内，就会对这个方法进行服务降级。

满足2个条件会触发熔断，
1：单位统计时长内请求数大于设置的最小值，
2.慢请求达到设置的比例。

异常比例
比例阈值 在0,1之间， 百分比，比如设置为0.5  也就是百分之50
最小请求数设置为5.
同时满足2个条件才可以出发降级
1.每秒请求数超过5个   >=5
2. 异常比例超过50%
设置一个接口， int age=10/0;
每秒访问10个请求 调用就会触发。


配置解释说明----
单独访问一次，必然来一次报错一次 (int age=10/0)，调一次错一次。
异常比例:当资源的每秒请求亮>=5,并且每秒异常总数占通过了的比例超过阈值(DegradeRule的count)之后，
资源进入降级状态，即在接下的时间窗口（DegradeRule的timeWindow，以s为单位）之内，
对这个方法的调用都会自动的返回，异常比率的阈值范围是[0.0,1.0]，代表0%--100%

开启jmeer后，直接高并发发送请求，多次调用达到我们的配置条件了，
断路器开启（保险丝跳闸），微服务不可用，不再报错error 而是服务降级了。

异常数----------------------------
通过计算发生异常的请求数于设置阈值对比的一种策略

当资源近（统计时长内）的异常数目超过阈值（也就是你设置的异常数）之后会进行服务降级，
统计时间窗口是可以设置的，之前的是不可以设置的，

---------------------------------------------------------------
热点规则（非常实用和常用）
何为热点？
热点即经常访问的数据，很多时候我们希望统计某个热点数据中访问频次最高的Top K数据，并对其访问进行限制。
比如：商品id作为参数， 统计一段时间内最常购买的商品id进行限制。
     用户id作为参数，针对一段时间内频繁访问的用户id进行限制。
热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，
对包含热点参数的资源调用进行限流。
热点参数限流可以看做是一种特殊的流量控制，仅对包含热点参数的资源调用生效。

怎么用 兜底方法为deal_testHotkey
@SentinelResource(value = "testHotkey",blockHandler = "deal_testHotkey")
sentinel中心必须对资源testHotkey设置热点。
参数索引为0,  下标从0开始。
单机阈值为1，
统计窗口时长为1秒

配置说明：每秒的请求超过1次QPS，就会触发降级，会调用兜底方法。

参数例外项
普通配置，超过1秒钟一个后，达到阈值会立刻进行限流
我们期望p1参数当它是某个特殊值时，它的限流值和平时不一样。

特列：当p1的值等于5的时候，阈值就可以为200 所以出现了参数例外项
参数类型为参数的具体类型，
参数值为5，阈值为200,。
一定要点击添加，否则不会保存。

之后进行测试，当p1的值为5，阈值就可以到200才会限流，否则不会限流，
不为5的时候会进行普通限流
注意jmeter调用例外项测试的时候要加参数

注意：
@SentinelResource
处理的是Sentinel控制台配的违规情况，有blockHandler方法配置的兜底处理

RuntimeException
int age=10/0  ; 这个是java程序运行时报的异常，@SentinelResource是不会管的。

总结：@SentinelResource主管配置出错，运行出错该走异常走异常。

-------------------------------------------------------------------------------------------
系统规则
Sentinel 系统自适应限流从整体维度对应用入口流量进行控制，
结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，  （重点）
通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。

Load 自适应（仅对 Linux/Unix-like 机器生效，window不行）：系统的 load1 作为启发指标，进行自适应系统保护。
当系统 load1 超过设定的启发值，且系统当前的并发线程数超过估算的系统容量时才会触发系统保护（BBR 阶段）。系统容量由系统的 maxQps * minRt 估算得出。设定参考值一般是 CPU cores * 2.5。

CPU usage（1.5.0+ 版本）：当系统 CPU 使用率超过阈值即触发系统保护（取值范围 0.0-1.0），比较灵敏。  百分比，和入口QPS差不多

平均 RT：当单台机器上所有入口流量的平均 RT 达到阈值即触发系统保护，单位是毫秒。 平均处理时间

并发线程数：当单台机器上所有入口流量的并发线程数达到阈值即触发系统保护。

入口 QPS：当单台机器上所有入口流量的 QPS 达到阈值即触发系统保护。 所有入口。

测试1：入口QPS（CPU），设置为1，1秒钟超过1次QPS，就会降级， 不管访问哪个接口 都是一样的， 但是这个限流方式不常用于生产，容易产生问题。





网址。
https://www.cnblogs.com/qlqwjy/p/13909052.html















